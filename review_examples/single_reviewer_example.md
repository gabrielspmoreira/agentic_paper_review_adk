Review for KDD Conference 

**Paper Title:** NV-Retriever: Improving text embedding models with effective hard-negative mining
 
**Summary:** This paper introduces a novel family of "positive-aware" hard-negative mining methods, specifically TopK-MarginPos and TopK-PercPos, designed to improve contrastive learning for text embedding models. These methods leverage the positive relevance score to dynamically filter out potential false negatives, leading to more accurate retrieval models. The authors conduct extensive ablation studies across various teacher models, mining configurations, and sampling strategies. A key demonstration of the methods' effectiveness is the training of NV-Retriever-v1, a state-of-the-art embedding model that achieved 1st place on the MTEB Retrieval leaderboard upon publication. The paper also provides insightful analyses of how these methods reduce false negatives and stabilize the training loss. 

**Strengths:** 
1. **Novelty and Algorithmic Contribution (High relevance for KDD):** The core contribution of "positive-aware" hard-negative mining methods (TopK-MarginPos and TopK-PercPos) is a clear and valuable algorithmic advancement. While the general idea of filtering false negatives exists, the proposed methods introduce a dynamic and data-driven approach by explicitly tying the negative threshold to the positive score, differentiating them from prior fixed-threshold or shifted-rank methods. The systematic exploration and validation of these methods are highly commendable. 
2. **Significant Empirical Impact and Scalability (High relevance for KDD):** Demonstrating that these mining methods enable the creation of NV-Retriever-v1, which achieved 1st place on the MTEB Retrieval leaderboard, is a powerful testament to their practical utility and real-world impact. The experiments are conducted at a large scale, involving substantial computational resources and diverse datasets, which aligns perfectly with KDD's emphasis on large-scale data mining applications. 
3. **Thorough Ablation Studies:** The paper provides a comprehensive set of ablation studies, systematically investigating: * The impact of different teacher models for mining hard-negatives (RQ1). * The effectiveness of ensembling hard-negatives from multiple teachers (RQ2). * A detailed comparison and configuration tuning of various hard-negative mining methods (RQ3.a), including traditional and proposed ones. * The effect of different sampling strategies from mined negatives. This level of empirical rigor is a significant strength. 
4. **Insightful Analysis of Mechanism:** Section 4.5 provides a crucial and highly valuable analysis of *why* the proposed methods work. * Using an LLM-as-a-judge to quantify the reduction in false negatives (Figure 3) provides strong empirical evidence for the methods' efficacy in cleaning the training data. This is an innovative and effective way to evaluate false negative removal. * Visualizing the score distributions and cross-entropy loss (Figure 4) clearly illustrates how positive-aware mining helps separate positive and negative embeddings and stabilizes the training process. 
5. **Good Reproducibility:** The paper provides detailed information on the experimental setup, including base models, teacher models, train/evaluation datasets, model architecture details, and training hyperparameters (Table 7, 8, 9). This contributes significantly to the reproducibility of the results. 

**Weaknesses and Areas for Improvement:** 
1. **Nuance on "Novelty":** While the paper claims a "novel family" of methods, it could be more precise in distinguishing the *novelty of the specific algorithms* (TopK-MarginPos, TopK-PercPos and their dynamic nature) from the *broader concept* of false negative filtering, which has been explored before (as acknowledged in Section 2.2.1). Rephrasing the contribution to emphasize the systematic development, extensive empirical validation, and demonstration of superiority *at scale* using these dynamic, positive-aware thresholds would be more accurate. 
2. **Deeper Intuition for Optimal Parameters:** The ablation studies identify optimal values for `abs_margin` (0.05) and `perc_margin` (95%). While empirical, a brief discussion on the intuition behind these optimal values or how they might generalize (or not) to different datasets/domains could be beneficial. For example, why 95% and not 90% or 100%? 
3. **Elaboration on "No-Dedup" Ensembling:** The finding that "keeping duplicate hard-negatives" during intra-sample ensembling improves performance (Table 2) is interesting. The proposed explanation ("increase its importance in the cross-entropy loss") is plausible but could be briefly elaborated or supported with a small conceptual example to solidify the intuition. 
4. **Prompt for LLM-as-a-judge:** For complete reproducibility of the false negative analysis, including the exact prompt used for the Llama 3.1 70b instruct LLM (or in an appendix) would be helpful. 
5. **Minor Typos/Formatting:** * "constrastive" (Abstract, 3.3.1, 4.5) should be "contrastive". * "leaderboard leaderboard" (4.4) is a repeated word. * Footnote 17 might be rephrased for clarity: "which increases the confidence of our LLM-as-judge approach" could imply the Mixtral model improves the Llama model's confidence, rather than just providing similar results that *reinforce confidence in the methodology*. Perhaps "which validates the robustness of our LLM-as-a-judge approach by yielding similar classification results." 

**Overall Recommendation for KDD:** 
This is a **strong paper** that makes a valuable contribution to the field of text embedding models, with a particular focus on a critical, yet often underexplored, aspect: hard-negative mining. The proposed positive-aware methods are intuitive, well-motivated, and empirically validated through comprehensive ablation studies and a large-scale SOTA model (NV-Retriever-v1). The detailed analysis of false negative reduction and loss stabilization adds significant insight. The paper directly aligns with KDD's emphasis on novel algorithmic contributions, large-scale empirical studies, and real-world impact. 
I recommend **Acceptance** for KDD.